{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "pdsi_file = 'pdsi.mon.mean.nc'\n",
    "pdsi_data = nc.Dataset(pdsi_file)\n",
    "\n",
    "pdsi_sc_file = 'pdsi.mon.mean.selfcalibrated.nc'\n",
    "pdsi_sc_data = nc.Dataset(pdsi_sc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    title: Global Monthly Dai Palmer Drought Severity Index\n",
      "    history: recreated Feb 2007 from data at NCAR webpage\n",
      "    References: https://www.psl.noaa.gov/data/gridded/data.pdsi.html\n",
      "    original_source: NCAR/UCAR: A Dai.\n",
      "    comments: This version of the dataset (1870-2005) supersedes the 1870-2003 version art PSD before Feb 2007\n",
      "    Conventions: COARDS\n",
      "    details: see ncar for more detials and updates\n",
      "http://www.cgd.ucar.edu/cas/catalog/climind/pdsi.html\n",
      "use reference Dai, A., K. E. Trenberth, and T. Qian, 2004: \n",
      "A global data set of Palmer Drought Severity Index for 1870-2002:\n",
      "Relationship with soil moisture and effects of surface warming. \n",
      "J. Hydrometeorology, 5, 1117-1130.\n",
      "    dataset_title: Palmer Drought Severity Index\n",
      "    dimensions(sizes): lon(144), lat(55), time(1632)\n",
      "    variables(dimensions): float32 pdsi(time, lat, lon), float32 lon(lon), float32 lat(lat), float64 time(time)\n",
      "    groups: \n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    title: Global Monthly Dai Palmer Drought Severity Index\n",
      "    history: created Apr 2013 from data at NCAR webpage:updated Nov 2015 from new dataset version\n",
      "    References: https://www.psl.noaa.gov/data/gridded/data.pdsi.html\n",
      "    original_source: NCAR/UCAR: A Dai http://www.cgd.ucar.edu/cas/catalog/climind/pdsi.html.\n",
      "    comments: original creation date: Thu Oct 25 15:25:40 MDT 2012 at NCAR. Updated at PSD Oct 2016 with corrected NCAR data\n",
      "    Conventions: COARDS\n",
      "    details: see ncar for more detials and updates\n",
      "    description: \n",
      "Monthly Self-calibrated Palmer Drought Severity Index (scPDSI)     \n",
      "calculated using observed surface air temperature (HadCRUT4 from   \n",
      "http://www.cru.uea.ac.uk/cru/data/temperature/ ) and               \n",
      "precipitation (from Dai et al. (1997, J.Clim: for 1870-1947) +     \n",
      "Chen et al. (2002, J. Hydromet.: for 1948-1978 + GPCP v2.2 for     \n",
      "1979-present. The Dai and Chen P data were adjusted to have the    \n",
      "same mean as the GPCP data over the 1979-1996 period).             \n",
      "Calibration (or reference) period is 1950-1979.                    \n",
      "Wind speed and air pressure data were from 20CR v2. Other data     \n",
      "were based on CRU TS3.22. Documention:  \t                   \n",
      "Dai, A., 2011a: Characteristics and trends in various forms of the \n",
      "Palmer Drought Severity Index (PDSI) during 1900-2008. J. Geophys. \n",
      "Res., 116, D12115, doi:10.1029/2010JD015541.\t\t\t   \n",
      "Dai, A., K. E. Trenberth, and T. Qian, 2004: A global data set of  \n",
      "Palmer Drought Severity Index for 1870-2002: Relationship with soil\n",
      "moisture and effects of surface warming. J. Hydrometeorology, 5,   \n",
      "1117-1130. Data source: Dr. A. Dai/NCAR (adai@ucar.edu). See       \n",
      "http://www.cgd.ucar.edu/cas/catalog/climind/pdsi.html for updates. \n",
      "WARNING: PDSI and scPDSI over the higher latitudes (e.g., >50deg.) \n",
      "may not be a good proxy of soil moisutre content. Also, PDSI and   \n",
      "scPDSI are highly autocorrelated indices not good at resolving     \n",
      "sub-seasonal variations.  Please use with caution!                 \n",
      "This is a normalized version so that every grid box has the same   \n",
      "s.d. as that in the central U.S. during the calibr. period (1950-79)\n",
      "    dataset_title: Palmer Drought Severity Index\n",
      "    dimensions(sizes): lon(144), lat(55), time(1980)\n",
      "    variables(dimensions): float32 pdsi(time, lat, lon), float32 lon(lon), float32 lat(lat), float64 time(time)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "print(pdsi_data)\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_sc_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lat(lat)\n",
      "    units: degrees_north\n",
      "    long_name: Latitude\n",
      "    actual_range: [-58.75  76.25]\n",
      "    standard_name: latitude\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = (55,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lon(lon)\n",
      "    units: degrees_east\n",
      "    long_name: Longitude\n",
      "    actual_range: [-178.75  178.75]\n",
      "    standard_name: longitude\n",
      "    axis: X\n",
      "unlimited dimensions: \n",
      "current shape = (144,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 pdsi(time, lat, lon)\n",
      "    statistic: Mean\n",
      "    missing_value: -99999.0\n",
      "    dataset: Dai Palmer Drought Severity Index\n",
      "    long_name: Monthly Global Palmer Drought Severity Index: v2\n",
      "    level_desc: Surface\n",
      "    var_desc: Palmer Drought Severity Index\n",
      "    add_offset: 0.0\n",
      "    scale_factor: 1.0\n",
      "    least_significant_digit: 2\n",
      "    units: Standardized Units of Relative Dry and Wet\n",
      "    actual_range: [-14.998861  14.999888]\n",
      "    valid_range: [-15.  15.]\n",
      "unlimited dimensions: time\n",
      "current shape = (1632, 55, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: hours since 1800-01-01 00:00:0.0\n",
      "    actual_range: [ 613608. 1805016.]\n",
      "    long_name: Time\n",
      "    delta_t: 0000-01-00 00:00:00\n",
      "    avg_period: 0000-01-00 00:00:00\n",
      "    standard_name: time\n",
      "    axis: T\n",
      "unlimited dimensions: time\n",
      "current shape = (1632,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lat(lat)\n",
      "    units: degrees_north\n",
      "    long_name: Latitude\n",
      "    actual_range: [-58.75  76.25]\n",
      "    standard_name: latitude\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = (55,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lon(lon)\n",
      "    units: degrees_east\n",
      "    long_name: Longitude\n",
      "    actual_range: [-178.75  178.75]\n",
      "    standard_name: longitude\n",
      "    axis: X\n",
      "unlimited dimensions: \n",
      "current shape = (144,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 pdsi(time, lat, lon)\n",
      "    statistic: Mean\n",
      "    missing_value: -99999.0\n",
      "    dataset: Dai Palmer Drought Severity Index: Self-calibrated\n",
      "    long_name: Monthly Self-calibrated Palmer Drought Severity Index using Penman-Monteith PE\n",
      "    level_desc: Surface\n",
      "    var_desc: Palmer Drought Severity Index\n",
      "    least_significant_digit: 2\n",
      "    units: Standardized Units of Relative Dry and Wet\n",
      "    actual_range: [-8.1602    8.160143]\n",
      "    valid_range: [-100.  100.]\n",
      "unlimited dimensions: time\n",
      "current shape = (1980, 55, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "================================\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: hours since 1800-01-01 00:00:0.0\n",
      "    actual_range: [ 438288. 1883904.]\n",
      "    long_name: Time\n",
      "    delta_t: 0000-01-00 00:00:00\n",
      "    avg_period: 0000-01-00 00:00:00\n",
      "    standard_name: time\n",
      "    axis: T\n",
      "unlimited dimensions: time\n",
      "current shape = (1980,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "print(pdsi_data['lat'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_data['lon'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_data['pdsi'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_data['time'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_sc_data['lat'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_sc_data['lon'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_sc_data['pdsi'])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_sc_data['time'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-58.75 -56.25 -53.75 -51.25 -48.75 -46.25 -43.75 -41.25 -38.75 -36.25\n",
      " -33.75 -31.25 -28.75 -26.25 -23.75 -21.25 -18.75 -16.25 -13.75 -11.25\n",
      "  -8.75  -6.25  -3.75  -1.25   1.25   3.75   6.25   8.75  11.25  13.75\n",
      "  16.25  18.75  21.25  23.75  26.25  28.75  31.25  33.75  36.25  38.75\n",
      "  41.25  43.75  46.25  48.75  51.25  53.75  56.25  58.75  61.25  63.75\n",
      "  66.25  68.75  71.25  73.75  76.25]\n",
      "\n",
      "================================\n",
      "\n",
      "[-58.75 -56.25 -53.75 -51.25 -48.75 -46.25 -43.75 -41.25 -38.75 -36.25\n",
      " -33.75 -31.25 -28.75 -26.25 -23.75 -21.25 -18.75 -16.25 -13.75 -11.25\n",
      "  -8.75  -6.25  -3.75  -1.25   1.25   3.75   6.25   8.75  11.25  13.75\n",
      "  16.25  18.75  21.25  23.75  26.25  28.75  31.25  33.75  36.25  38.75\n",
      "  41.25  43.75  46.25  48.75  51.25  53.75  56.25  58.75  61.25  63.75\n",
      "  66.25  68.75  71.25  73.75  76.25]\n",
      "\n",
      "================================\n",
      "\n",
      "[-178.75 -176.25 -173.75 -171.25 -168.75 -166.25 -163.75 -161.25 -158.75\n",
      " -156.25 -153.75 -151.25 -148.75 -146.25 -143.75 -141.25 -138.75 -136.25\n",
      " -133.75 -131.25 -128.75 -126.25 -123.75 -121.25 -118.75 -116.25 -113.75\n",
      " -111.25 -108.75 -106.25 -103.75 -101.25  -98.75  -96.25  -93.75  -91.25\n",
      "  -88.75  -86.25  -83.75  -81.25  -78.75  -76.25  -73.75  -71.25  -68.75\n",
      "  -66.25  -63.75  -61.25  -58.75  -56.25  -53.75  -51.25  -48.75  -46.25\n",
      "  -43.75  -41.25  -38.75  -36.25  -33.75  -31.25  -28.75  -26.25  -23.75\n",
      "  -21.25  -18.75  -16.25  -13.75  -11.25   -8.75   -6.25   -3.75   -1.25\n",
      "    1.25    3.75    6.25    8.75   11.25   13.75   16.25   18.75   21.25\n",
      "   23.75   26.25   28.75   31.25   33.75   36.25   38.75   41.25   43.75\n",
      "   46.25   48.75   51.25   53.75   56.25   58.75   61.25   63.75   66.25\n",
      "   68.75   71.25   73.75   76.25   78.75   81.25   83.75   86.25   88.75\n",
      "   91.25   93.75   96.25   98.75  101.25  103.75  106.25  108.75  111.25\n",
      "  113.75  116.25  118.75  121.25  123.75  126.25  128.75  131.25  133.75\n",
      "  136.25  138.75  141.25  143.75  146.25  148.75  151.25  153.75  156.25\n",
      "  158.75  161.25  163.75  166.25  168.75  171.25  173.75  176.25  178.75]\n",
      "\n",
      "================================\n",
      "\n",
      "[-178.75 -176.25 -173.75 -171.25 -168.75 -166.25 -163.75 -161.25 -158.75\n",
      " -156.25 -153.75 -151.25 -148.75 -146.25 -143.75 -141.25 -138.75 -136.25\n",
      " -133.75 -131.25 -128.75 -126.25 -123.75 -121.25 -118.75 -116.25 -113.75\n",
      " -111.25 -108.75 -106.25 -103.75 -101.25  -98.75  -96.25  -93.75  -91.25\n",
      "  -88.75  -86.25  -83.75  -81.25  -78.75  -76.25  -73.75  -71.25  -68.75\n",
      "  -66.25  -63.75  -61.25  -58.75  -56.25  -53.75  -51.25  -48.75  -46.25\n",
      "  -43.75  -41.25  -38.75  -36.25  -33.75  -31.25  -28.75  -26.25  -23.75\n",
      "  -21.25  -18.75  -16.25  -13.75  -11.25   -8.75   -6.25   -3.75   -1.25\n",
      "    1.25    3.75    6.25    8.75   11.25   13.75   16.25   18.75   21.25\n",
      "   23.75   26.25   28.75   31.25   33.75   36.25   38.75   41.25   43.75\n",
      "   46.25   48.75   51.25   53.75   56.25   58.75   61.25   63.75   66.25\n",
      "   68.75   71.25   73.75   76.25   78.75   81.25   83.75   86.25   88.75\n",
      "   91.25   93.75   96.25   98.75  101.25  103.75  106.25  108.75  111.25\n",
      "  113.75  116.25  118.75  121.25  123.75  126.25  128.75  131.25  133.75\n",
      "  136.25  138.75  141.25  143.75  146.25  148.75  151.25  153.75  156.25\n",
      "  158.75  161.25  163.75  166.25  168.75  171.25  173.75  176.25  178.75]\n",
      "\n",
      "================================\n",
      "\n",
      "[ 613608.  614352.  615024. ... 1803552. 1804296. 1805016.]\n",
      "\n",
      "================================\n",
      "\n",
      "[ 438288.  439032.  439704. ... 1882440. 1883184. 1883904.]\n"
     ]
    }
   ],
   "source": [
    "print(pdsi_data['lat'][:])\n",
    "print('\\n================================\\n')       #latitude coordinates are the same\n",
    "print(pdsi_sc_data['lat'][:])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_data['lon'][:])\n",
    "print('\\n================================\\n')       #longitude coordinates are the same\n",
    "print(pdsi_sc_data['lon'][:])\n",
    "print('\\n================================\\n')\n",
    "print(pdsi_data['time'][:])                         #begins in 1870\n",
    "print('\\n================================\\n')       #times are different\n",
    "print(pdsi_sc_data['time'][:])                      #begins in 1850"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.25]\n",
      "[31.25]\n",
      "(1632,)\n",
      "[1805016.]\n",
      "isLeap is True\n",
      "weirdGap is False\n"
     ]
    }
   ],
   "source": [
    "tabora_coordinates = -6, 32    #North (lat), East (lon)\n",
    "\n",
    "print(pdsi_data['lat'][21:22])\n",
    "print(pdsi_data['lon'][84:85])\n",
    "print(pdsi_data['time'][:].shape)\n",
    "print(pdsi_data['time'][pdsi_data['time'][:].shape[0] - 1 : pdsi_data['time'][:].shape[0] ])\n",
    "\n",
    "is_leap = False\n",
    "inconsistent_gap = False\n",
    "for i in range(pdsi_data['time'][:].shape[0] - 2):\n",
    "    # print(pdsi_data['time'][i+1:i+2] - pdsi_data['time'][i: i+1])\n",
    "    gap = pdsi_data['time'][i+1:i+2] - pdsi_data['time'][i: i+1]\n",
    "    if(gap/24 == 29):\n",
    "        is_leap = True\n",
    "    if(gap < 672 or gap > 744):\n",
    "        inconsistent_gap = True\n",
    "print(f'isLeap is {is_leap}')\n",
    "print(f'weirdGap is {inconsistent_gap}')\n",
    "\n",
    "#For time, the gaps between the numbers are all different, considering the number of days in each month\n",
    "#There are leap years in the time array, but the time array seems wrong/mismatched? There aren't enough leap years and the number of days seems out of order\n",
    "#Nonetheless, the time array is consisently increasing anyways, with no gap between values exceeding 31 days or smaller than 28"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#IMPORTs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta, date\n",
    "import calendar\n",
    "from scipy.stats import pearsonr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Managing PDSI\n",
      "(1632, 1, 1)\n",
      "(1632,)\n",
      "\n",
      "====================================\n",
      "\n",
      "Managing PDSI SC\n",
      "(1980, 1, 1)\n",
      "(1980,)\n",
      "\n",
      "====================================\n",
      "\n",
      "Managing PDSI Time\n",
      "(1632,)\n",
      "(1632,)\n",
      "\n",
      "====================================\n",
      "\n",
      "Managing PDSI SC Time\n",
      "(1980, 1, 1)\n",
      "(1980,)\n"
     ]
    }
   ],
   "source": [
    "#at Tabora\n",
    "#pdsi is time, lat, lon\n",
    "print('Managing PDSI')\n",
    "print(pdsi_data['pdsi'][:, 21:22, 84:85].shape)\n",
    "pdsi_array = pdsi_data['pdsi'][:, 21:22, 84:85].reshape(-1)\n",
    "print(pdsi_array.shape)\n",
    "print('\\n====================================\\n')\n",
    "print('Managing PDSI SC')\n",
    "print(pdsi_sc_data['pdsi'][:, 21:22, 84:85].shape)\n",
    "pdsi_sc_array = pdsi_sc_data['pdsi'][:, 21:22, 84:85].reshape(-1)\n",
    "print(pdsi_sc_array.shape)\n",
    "print('\\n====================================\\n')\n",
    "print('Managing PDSI Time')\n",
    "print(pdsi_data['time'][:].shape)\n",
    "pdsi_time_array = pdsi_data['time'][:].reshape(-1)     #time is already 1D array, not needed\n",
    "print(pdsi_time_array.shape)\n",
    "print('\\n====================================\\n')\n",
    "print('Managing PDSI SC Time')\n",
    "print(pdsi_sc_data['pdsi'][:, 21:22, 84:85].shape)\n",
    "pdsi_sc_time_array = pdsi_sc_data['time'][:].reshape(-1)\n",
    "print(pdsi_sc_time_array.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units are: hours since 1800-01-01 00:00:0.0\n",
      "\n",
      "Getting invalid indices...\n",
      "There are 481 invalid indices.\n",
      "\n",
      "===================================\n",
      "\n",
      "Getting invalid indices...\n",
      "There are 676 invalid indices.\n",
      "\n",
      "===================================\n",
      "\n",
      "Getting datetime for PDSI time\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "Starts on 1870-01-01\n",
      "Ends on 2005-12-01\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "Starts on 1850-01-01\n",
      "Ends on 2014-12-01\n"
     ]
    }
   ],
   "source": [
    "print(f'units are: {pdsi_data.variables[\"time\"].units}')    #no calendar in variable field - makes this a little harder\n",
    "\n",
    "print()\n",
    "\n",
    "def get_invalid_indices(array):\n",
    "    invalid_indices = []\n",
    "    print('Getting invalid indices...')\n",
    "    for i in range(len(pdsi_array)):\n",
    "        # print(f'value is {array[i]} and type is {type(array[i]).__name__}')\n",
    "        if type(array[i]).__name__ == 'MaskedConstant':\n",
    "            invalid_indices.append(i)\n",
    "    print(f'There are {len(invalid_indices)} invalid indices.')\n",
    "    return invalid_indices\n",
    "\n",
    "invalid_pdsi_array_indices = get_invalid_indices(pdsi_array)\n",
    "pdsi_mask = pdsi_array.mask     #note, run the previous cell before rerunning this one - otherwise type errors\n",
    "pdsi_array = pdsi_array.filled(fill_value=-999)     #convert masked array to regular array\n",
    "\n",
    "print('\\n===================================\\n')\n",
    "\n",
    "invalid_pdsi_sc_array_indices = get_invalid_indices(pdsi_sc_array)\n",
    "pdsi_sc_mask = pdsi_sc_array.mask\n",
    "pdsi_sc_array = pdsi_sc_array.filled(fill_value=-999)       #convert masked array to regular array\n",
    "\n",
    "print('\\n===================================\\n')\n",
    "\n",
    "print('Getting datetime for PDSI time')\n",
    "pdsi_all_start = date(1800, 1, 1)\n",
    "\n",
    "print()\n",
    "\n",
    "pdsi_time_first = pdsi_data['time'][0:1].filled(fill_value=-999)\n",
    "print(type(pdsi_time_first))\n",
    "pdsi_delta = timedelta(hours=pdsi_time_first[0])\n",
    "print(f'Starts on {pdsi_all_start + pdsi_delta}')\n",
    "print(f'Ends on {pdsi_all_start + timedelta(hours=pdsi_time_array[len(pdsi_time_array) - 1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "pdsi_sc_time_first = pdsi_sc_data['time'][0:1].filled(fill_value=-999)\n",
    "print(type(pdsi_sc_time_first))\n",
    "pdsi_sc_delta = timedelta(hours=pdsi_sc_time_first[0])\n",
    "print(f'Starts on {pdsi_all_start + pdsi_sc_delta}')\n",
    "print(f'Ends on {pdsi_all_start + timedelta(hours=pdsi_sc_time_array[len(pdsi_sc_time_array) - 1])}')\n",
    "\n",
    "#use pdsi_all_start to get the dates of all the numbers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#FUNCTION FOR GETTING CSVS\n",
    "\n",
    "# use date_ref as the date object to add the time delta to\n",
    "#this assumes that data_array and time_array are the same size and correspond to one another\n",
    "def get_monthly_df(data_array, time_array, date_ref):\n",
    "    print('Getting data as dictionary...')\n",
    "\n",
    "    monthly_dict = {        #doesn't make much sense to add an annual column for pdsi...\n",
    "        'Year': [],\n",
    "        'January': [],\n",
    "        'February': [],\n",
    "        'March': [],\n",
    "        'April': [],\n",
    "        'May': [],\n",
    "        'June': [],\n",
    "        'July': [],\n",
    "        'August': [],\n",
    "        'September': [],\n",
    "        'October': [],\n",
    "        'November': [],\n",
    "        'December': []\n",
    "    }\n",
    "\n",
    "    for i in range(len(data_array)):\n",
    "        date = date_ref + timedelta(hours=time_array[i])\n",
    "        year, month = date.year, date.month\n",
    "\n",
    "        if(month == 1):\n",
    "            monthly_dict['Year'].append(year)       #update year only once every 12 months (in January)\n",
    "\n",
    "        monthly_dict[calendar.month_name[month]].append(data_array[i])      #add data for that year and month to corresponding location\n",
    "\n",
    "    monthly_df = pd.DataFrame(monthly_dict)\n",
    "    print('Done transforming data. Resultant dataframe is: ')\n",
    "    print(monthly_df)\n",
    "\n",
    "    return monthly_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Assumes you are using a df in the style of the one created by get_monthly_df\n",
    "def get_average_monthly_df(monthly_df):\n",
    "    print(\"Getting average monthly data...\")\n",
    "\n",
    "    monthly_average_dict = {\n",
    "        'Year': [],\n",
    "        'Average': []\n",
    "    }\n",
    "\n",
    "    for row in range(monthly_df.shape[0]):\n",
    "\n",
    "        # skip this row if it contains -999\n",
    "        if(-999 in monthly_df.iloc[row].values):\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            row_mean = 0\n",
    "            for column in range(1, 13):\n",
    "                row_mean += monthly_df.iloc[row][calendar.month_name[column]]\n",
    "\n",
    "            row_mean = row_mean/12\n",
    "            monthly_average_dict['Year'].append(monthly_df.iloc[row]['Year'])\n",
    "            monthly_average_dict['Average'].append(row_mean)\n",
    "\n",
    "    monthly_average_df = pd.DataFrame(monthly_average_dict)\n",
    "    print('Done calculating averages. Resultant dataframe is: ')\n",
    "    print(monthly_average_df)\n",
    "\n",
    "    return monthly_average_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data as dictionary...\n",
      "Done transforming data. Resultant dataframe is: \n",
      "     Year     January    February       March       April         May  \\\n",
      "0    1870 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "1    1871 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "2    1872 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "3    1873 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "4    1874 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "..    ...         ...         ...         ...         ...         ...   \n",
      "131  2001    0.751824    0.398075    0.467179    0.444795    0.251886   \n",
      "132  2002    1.141401    1.285129    1.416445    1.313549    1.214510   \n",
      "133  2003   -0.702344   -1.435134   -2.404176   -2.845693   -2.736134   \n",
      "134  2004   -3.949282   -4.493617   -4.782063   -5.238981   -5.185505   \n",
      "135  2005    0.409329    0.168737    0.185230    0.547481    0.977692   \n",
      "\n",
      "           June        July      August   September     October    November  \\\n",
      "0   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "1   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "2   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "3   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "4   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "131    0.248123    0.717805    0.771343    1.055452    1.013256    1.070348   \n",
      "132    1.139254    1.079066    0.904713    0.855349    1.099821    1.102579   \n",
      "133   -2.724200   -2.672214   -2.613832   -2.620058   -2.406896   -2.424246   \n",
      "134   -4.985554   -4.821054   -4.536236    0.450073    0.469785    0.606425   \n",
      "135    1.069780    1.168577    1.308274    1.594476    0.012387   -0.515354   \n",
      "\n",
      "       December  \n",
      "0   -999.000000  \n",
      "1   -999.000000  \n",
      "2   -999.000000  \n",
      "3   -999.000000  \n",
      "4   -999.000000  \n",
      "..          ...  \n",
      "131    1.036024  \n",
      "132   -0.145514  \n",
      "133   -3.355633  \n",
      "134    0.600687  \n",
      "135   -1.110922  \n",
      "\n",
      "[136 rows x 13 columns]\n",
      "\n",
      "========================\n",
      "\n",
      "Getting data as dictionary...\n",
      "Done transforming data. Resultant dataframe is: \n",
      "     Year     January    February       March       April         May  \\\n",
      "0    1850 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "1    1851 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "2    1852 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "3    1853 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "4    1854 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "..    ...         ...         ...         ...         ...         ...   \n",
      "160  2010   -0.750143    0.585349    0.040461   -1.964985   -2.100832   \n",
      "161  2011   -1.260548   -1.419650   -0.411496   -1.558823   -1.632407   \n",
      "162  2012   -0.214492   -0.186671   -0.643837   -1.460170   -1.764998   \n",
      "163  2013    0.026983   -0.615458   -0.174764   -0.461523   -1.101558   \n",
      "164  2014    0.011892   -0.384995   -0.523699   -1.867032   -2.624389   \n",
      "\n",
      "           June        July      August   September     October    November  \\\n",
      "0   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "1   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "2   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "3   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "4   -999.000000 -999.000000 -999.000000 -999.000000 -999.000000 -999.000000   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "160   -2.023519   -1.925185   -1.868824   -1.855336   -1.891248   -2.018221   \n",
      "161   -1.509528   -1.445037   -1.413961    0.440690    1.489790    1.664048   \n",
      "162   -1.791541   -1.802010   -1.495971   -1.616529    0.513684    0.929161   \n",
      "163   -1.069397   -1.029568   -1.030941   -0.672154   -1.271633   -0.971977   \n",
      "164   -2.552138   -2.446546   -2.144351   -1.723557    2.229815    1.970950   \n",
      "\n",
      "       December  \n",
      "0   -999.000000  \n",
      "1   -999.000000  \n",
      "2   -999.000000  \n",
      "3   -999.000000  \n",
      "4   -999.000000  \n",
      "..          ...  \n",
      "160   -1.420793  \n",
      "161    1.880004  \n",
      "162    2.121974  \n",
      "163    1.375459  \n",
      "164    1.189712  \n",
      "\n",
      "[165 rows x 13 columns]\n",
      "\n",
      "========================\n",
      "\n",
      "Getting average monthly data...\n",
      "Done calculating averages. Resultant dataframe is: \n",
      "      Year   Average\n",
      "0   1894.0  0.113790\n",
      "1   1895.0 -2.849903\n",
      "2   1904.0 -4.066130\n",
      "3   1905.0 -2.770973\n",
      "4   1906.0 -0.421541\n",
      "..     ...       ...\n",
      "90  2001.0  0.685509\n",
      "91  2002.0  1.033859\n",
      "92  2003.0 -2.411713\n",
      "93  2004.0 -2.988777\n",
      "94  2005.0  0.484641\n",
      "\n",
      "[95 rows x 2 columns]\n",
      "\n",
      "========================\n",
      "\n",
      "Getting average monthly data...\n",
      "Done calculating averages. Resultant dataframe is: \n",
      "       Year   Average\n",
      "0    1894.0 -2.046298\n",
      "1    1895.0 -3.408646\n",
      "2    1899.0 -6.939312\n",
      "3    1901.0 -7.100239\n",
      "4    1903.0  1.416210\n",
      "..      ...       ...\n",
      "102  2010.0 -1.432773\n",
      "103  2011.0 -0.431410\n",
      "104  2012.0 -0.617617\n",
      "105  2013.0 -0.583044\n",
      "106  2014.0 -0.738695\n",
      "\n",
      "[107 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pdsi_df = get_monthly_df(pdsi_array, pdsi_time_array, pdsi_all_start)\n",
    "\n",
    "print('\\n========================\\n')\n",
    "\n",
    "pdsi_sc_df= get_monthly_df(pdsi_sc_array, pdsi_sc_time_array, pdsi_all_start)\n",
    "\n",
    "print('\\n========================\\n')\n",
    "\n",
    "pdsi_annual_avg= get_average_monthly_df(pdsi_df)\n",
    "\n",
    "print('\\n========================\\n')\n",
    "\n",
    "pdsi_sc_annual_avg= get_average_monthly_df(pdsi_sc_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#Downloading CSV Files\n",
    "\n",
    "pdsi_filename = f'C:\\\\Users\\\\Cecile Dai\\\\Documents\\\\Professional\\\\McGill University\\\\IOWC\\\\Other Datasets\\\\Alternative_Datasets\\\\DAI PDSI\\\\tabora_pdsi.csv'\n",
    "\n",
    "pdsi_sc_filename = f'C:\\\\Users\\\\Cecile Dai\\\\Documents\\\\Professional\\\\McGill University\\\\IOWC\\\\Other Datasets\\\\Alternative_Datasets\\\\DAI PDSI\\\\tabora_pdsi_sc.csv'\n",
    "\n",
    "pdsi_avg_filename = f'C:\\\\Users\\\\Cecile Dai\\\\Documents\\\\Professional\\\\McGill University\\\\IOWC\\\\Other Datasets\\\\Alternative_Datasets\\\\DAI PDSI\\\\tabora_pdsi_avg.csv'\n",
    "\n",
    "pdsi_sc_avg_filename = f'C:\\\\Users\\\\Cecile Dai\\\\Documents\\\\Professional\\\\McGill University\\\\IOWC\\\\Other Datasets\\\\Alternative_Datasets\\\\DAI PDSI\\\\tabora_pdsi_sc_avg.csv'\n",
    "\n",
    "pdsi_df.to_csv(pdsi_filename, index=False)\n",
    "pdsi_sc_df.to_csv(pdsi_sc_filename, index=False)\n",
    "pdsi_annual_avg.to_csv(pdsi_avg_filename, index=False)\n",
    "pdsi_sc_annual_avg.to_csv(pdsi_sc_avg_filename, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PDSI and SC PDSI Correlations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "#Assumes you're correlating two chronological year x 12 month dataframes\n",
    "#Choice to correlate either monthly columns or yearly rows\n",
    "\n",
    "# FIND SOME WAY TO DEAL WITH MISSING VALUES\n",
    "\n",
    "def correl_dfs_by_date(df_1, df_2, is_month):\n",
    "    print('Getting correlation coefficients for two dataframes organized by date and month...')\n",
    "    #Make sure they're going over the same time frame\n",
    "\n",
    "    #Check which one starts earlier\n",
    "    earliest_matching_year = df_2.iloc[0]['Year']\n",
    "    latest_matching_year = df_1.iloc[df_1.shape[0] - 1]['Year']\n",
    "\n",
    "    if df_1.iloc[0]['Year'] > df_2.iloc[0]['Year']:     # if df_1 starts later\n",
    "        earliest_matching_year = df_1.iloc[0]['Year']\n",
    "\n",
    "    if df_1.iloc[df_1.shape[0] - 1]['Year'] > df_2.iloc[df_2.shape[0] - 1]['Year']:     # if df_1 ends later\n",
    "        latest_matching_year = df_2.iloc[df_2.shape[0] - 1]['Year']\n",
    "\n",
    "    print(f'Year range is {earliest_matching_year} to {latest_matching_year}')\n",
    "\n",
    "    correl_dict = { }       # append arrays to this, too lazy to type everything out\n",
    "\n",
    "    if is_month == True:    # collect monthly correlations\n",
    "\n",
    "        for month in range(1, 13):\n",
    "\n",
    "            # print(df_1.loc[df_1['Year'] >= earliest_matching_year])\n",
    "\n",
    "            month_arr_1 = df_1.loc[(df_1['Year'] >= earliest_matching_year) & (df_1['Year'] <= latest_matching_year)][calendar.month_name[month]]\n",
    "            month_arr_2 = df_2.loc[(df_2['Year'] >= earliest_matching_year) & (df_2['Year'] <= latest_matching_year)][calendar.month_name[month]]\n",
    "\n",
    "            month_arr_1 = month_arr_1.tolist()\n",
    "            month_arr_2 = month_arr_2.tolist()\n",
    "\n",
    "            # temporary way of dealing with null values: if a row contains a missing value, don't copy to new array\n",
    "            # should be fine since now both lists cover the same time\n",
    "            # btw we're making copies bc pop() by index has issues when the length of the list is changing\n",
    "\n",
    "            month_arr_1_copy = []\n",
    "            month_arr_2_copy = []\n",
    "\n",
    "            for element in range(len(month_arr_1)):\n",
    "                if month_arr_1[element] == -999 or month_arr_2[element] == -999:\n",
    "                    continue\n",
    "                else:\n",
    "                    month_arr_1_copy.append(month_arr_1[element])\n",
    "                    month_arr_2_copy.append(month_arr_2[element])\n",
    "\n",
    "            # print(month_arr_1_copy)\n",
    "            # print(month_arr_2_copy)\n",
    "\n",
    "            correl_dict[calendar.month_name[month]] = [pearsonr(month_arr_1_copy, month_arr_2_copy)[0]]\n",
    "\n",
    "    else:   # collect annual correlations\n",
    "\n",
    "        for year in range(int(earliest_matching_year), int(latest_matching_year + 1)):\n",
    "            year_arr_1 = df_1.loc[df_1['Year'] == year].drop(columns=['Year'])\n",
    "            year_arr_2 = df_2.loc[df_2['Year'] == year].drop(columns=['Year'])\n",
    "\n",
    "            year_arr_1 = year_arr_1.values.flatten().tolist()\n",
    "            year_arr_2 = year_arr_2.values.flatten().tolist()\n",
    "\n",
    "            # print(year_arr_1)\n",
    "            # print(year_arr_2)\n",
    "\n",
    "            # problem if array is constant with correl function, so append NaN in that case\n",
    "            if (year_arr_1.count(year_arr_1[0]) == len(year_arr_1)) or (year_arr_2.count(year_arr_2[0]) == len(year_arr_2)):\n",
    "                correl_dict[year] = [float('nan')]\n",
    "            else:\n",
    "                correl_dict[year] = [pearsonr(year_arr_1, year_arr_2)[0]]\n",
    "\n",
    "    correl_df = pd.DataFrame(correl_dict)\n",
    "\n",
    "    print('Done correlating dataframes. Resultant correlation dataframe is: ')\n",
    "    print(correl_df)\n",
    "\n",
    "    return correl_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting correlation coefficients for two dataframes organized by date and month...\n",
      "Year range is 1870.0 to 2005.0\n",
      "Done correlating dataframes. Resultant correlation dataframe is: \n",
      "    January  February     March     April       May      June      July  \\\n",
      "0  0.811187  0.809695  0.831809  0.789301  0.614888  0.630902  0.641644   \n",
      "\n",
      "     August  September   October  November  December  \n",
      "0  0.653347    0.61286  0.668642  0.807716  0.807572  \n",
      "\n",
      "==================================\n",
      "\n",
      "Getting correlation coefficients for two dataframes organized by date and month...\n",
      "Year range is 1870.0 to 2005.0\n",
      "Done correlating dataframes. Resultant correlation dataframe is: \n",
      "   1870  1871  1872  1873  1874  1875  1876  1877  1878  1879  ...      1996  \\\n",
      "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ... -0.140939   \n",
      "\n",
      "       1997     1998      1999      2000      2001     2002     2003  \\\n",
      "0 -0.166714 -0.10065  0.309541  0.911475  0.063683 -0.44302  0.92767   \n",
      "\n",
      "       2004      2005  \n",
      "0  0.769115 -0.061509  \n",
      "\n",
      "[1 rows x 136 columns]\n"
     ]
    }
   ],
   "source": [
    "pdsi_monthly_correl = correl_dfs_by_date(pdsi_df, pdsi_sc_df, True)\n",
    "\n",
    "print('\\n==================================\\n')\n",
    "\n",
    "pdsi_yearly_correl = correl_dfs_by_date(pdsi_df, pdsi_sc_df, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "# DOWNLOAD CORRELATION FILES\n",
    "\n",
    "pdsi_monthly_correl_filename = f'C:\\\\Users\\\\Cecile Dai\\\\Documents\\\\Professional\\\\McGill University\\\\IOWC\\\\Other Datasets\\\\Alternative_Datasets\\\\DAI PDSI\\\\tabora_pdsi_correl_monthly.csv'\n",
    "\n",
    "pdsi_yearly_correl_filename = f'C:\\\\Users\\\\Cecile Dai\\\\Documents\\\\Professional\\\\McGill University\\\\IOWC\\\\Other Datasets\\\\Alternative_Datasets\\\\DAI PDSI\\\\tabora_pdsi_correl_yearly.csv'\n",
    "\n",
    "pdsi_monthly_correl.to_csv(pdsi_monthly_correl_filename, index=False)\n",
    "pdsi_yearly_correl.to_csv(pdsi_yearly_correl_filename, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}